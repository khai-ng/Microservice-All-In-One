version: '3.4'

services:
    ## Kafka
    # kafka-ui:
    #     container_name: kafka-ui
    #     image: provectuslabs/kafka-ui:latest
    #     depends_on:
    #         - kafka
    #         - zookeeper
    #         # - schemaregistry
    #         # - kafka-connect
    #     networks:
    #         - local 

    # zookeeper:
    #     image: confluentinc/cp-zookeeper:7.6.0
    #     networks:
    #         - local 
 
    # kafka:
    #     image: confluentinc/cp-kafka:7.6.0
    #     depends_on:
    #         - zookeeper
    #     networks:
    #         - local 

    # schemaregistry:
    #     image: confluentinc/cp-schema-registry:7.6.0
    #     depends_on:
    #         - kafka
    #     networks:
    #         - local 

    # kafka-connect:
    #     image: confluentinc/cp-kafka-connect:7.6.0
    #     depends_on:
    #         - kafka
    #         - schemaregistry
    #     networks:
    #         - local 

    ## Services
    mysql:
        image: mysql:8.3.0
        restart: on-failure
        networks:
            - local

    ## mongoimport --jsonArray -h 127.0.0.1:27017 -d product -c all_beauty -u admin -p 1234 --authenticationDatabase admin --file /data/json/meta_All_Beauty-1.json
    product-db-1:
        image: mongo:7.0.9
        restart: on-failure
        networks:
            - local
    
    product-db-2:
        image: mongo:7.0.9
        restart: on-failure
        networks:
            - local
    
    product-db-3:
        image: mongo:7.0.9
        restart: on-failure
        networks:
            - local

    product-db-4:
        image: mongo:7.0.9
        restart: on-failure
        networks:
            - local
        
    mongo-express:
        image: mongo-express:1.0.2-20-alpine3.19
        depends_on:
            - product-db-1
        networks:
            - local

    identity-api:
        image: ${DOCKER_REGISTRY-}identityapi
        build:
            context: .
            dockerfile: src/Services/Identity/Identity.API/Dockerfile
        # depends_on:
        #     kafka:
        #         condition: service_healthy
        networks:
            - local
        logging:
            driver: fluentd
            options:
                fluentd-async: "true"
                tag: host.identity

    # employee-api:
    #     image: ${DOCKER_REGISTRY-}employeeapi
    #     build:
    #         context: .
    #         dockerfile: src/Services/EmployeeMgt/EmployeeMgt.API/Dockerfile
    #     # depends_on:
    #     #     kafka:
    #     #         condition: service_healthy 
    #     networks:
    #         - local
    #     logging:
    #         driver: fluentd
    #         options:
    #             fluentd-async: "true"
    #             tag: host.employee-mgt
                
    product-api:
        image: ${DOCKER_REGISTRY-}productapi
        build:
            context: .
            dockerfile: src/Services/Product.API/Dockerfile
        networks:
            - local
        logging:
            driver: fluentd
            options:
                fluentd-async: "true"
                tag: host.product

    web-apigateway:
        image: ${DOCKER_REGISTRY-}webapigateway
        build:
            context: .
            dockerfile: src/ApiGateways/Web.ApiGateway/Dockerfile
        depends_on:
            - identity-api
            # - employee-api
        networks:
            - local
        logging:
            driver: fluentd
            options:
                fluentd-async: "true"
                tag: host.web-apigateway  

    ## Monitoring
    # fluent-bit:
    #     image: fluent/fluent-bit:2.2.2
    #     networks:
    #         - local

    ##Fluent bit - Elasticsearch, Kibana stack
    # elasticsearch:
    #     image: docker.elastic.co/elasticsearch/elasticsearch:7.17.18
    #     restart: on-failure
    #     networks:
    #         - local
    #     depends_on:
    #         - fluent-bit
    #     logging:
    #         driver: fluentd
    #         options:
    #             fluentd-async: "true"
    #             tag: logger.es

    # kibana:
    #     image: docker.elastic.co/kibana/kibana:7.17.18
    #     restart: on-failure
    #     networks:
    #         - local
    #     depends_on:
    #         - fluent-bit
    #         - elasticsearch
    #     logging:
    #         driver: fluentd
    #         options:
    #             fluentd-async: "true"
    #             tag: logger.kibana

    ##Fluent bit - Prometheus, Loki, Grafana stack
    # loki:
    #     image: grafana/loki:2.9.4
    #     volumes:
    #         - ./loki:/etc/loki
    #     ports:
    #         - 3100:3100
    #     command: "-config.file=/etc/loki/local-config.yaml"
    #     networks:
    #         - local

    # prometheus:
    #     image: prom/prometheus:v2.49.1
    #     command:
    #         - '--config.file=/etc/prometheus/prometheus.yml'
    #         - '--storage.tsdb.path=/prometheus'
    #         - '--web.console.libraries=/etc/prometheus/console_libraries'
    #         - '--web.console.templates=/etc/prometheus/consoles'
    #         - '--storage.tsdb.retention.time=200h'
    #         - '--web.enable-lifecycle'
    #     restart: unless-stopped
    #     networks:
    #         - local
    #     labels:
    #         org.label-schema.group: "monitoring"

    # grafana:
    #     image: grafana/grafana:10.2.4
    #     networks:
    #         - local
    #     depends_on:
    #         - fluent-bit
    #         # - elasticsearch
    #         - loki

    # nodeexporter:
    #     image: prom/node-exporter:v1.7.0
    #     user: root
    #     privileged: true
    #     volumes:
    #         - /proc:/host/proc:ro
    #         - /sys:/host/sys:ro
    #         - /:/rootfs:ro
    #     command:
    #         - '--path.procfs=/host/proc'
    #         - '--path.rootfs=/rootfs'
    #         - '--path.sysfs=/host/sys'
    #         - '--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)'
    #     restart: unless-stopped
    #     expose:
    #         - 9100
    #     networks:
    #         - local
    #     labels:
    #         org.label-schema.group: "monitoring"

    # cadvisor:
    #     image: gcr.io/google-containers/cadvisor:v0.36.0
    #     volumes:
    #         - /:/rootfs:ro
    #         - /var/run:/var/run:rw
    #         - /sys:/sys:ro
    #         - /var/lib/docker:/var/lib/docker:ro
    #         - /dev/disk/:/dev/disk:ro
    #         #- /cgroup:/cgroup:ro #doesn't work on MacOS only for Linux
    #     restart: unless-stopped
    #     expose:
    #         - 8080
    #     networks:
    #         - local
    #     labels:
    #         org.label-schema.group: "monitoring"

    # pushgateway:
    #     image: prom/pushgateway:v1.6.2
    #     container_name: pushgateway
    #     restart: unless-stopped
    #     expose:
    #         - 9091
    #     networks:
    #         - local
    #     labels:
    #         org.label-schema.group: "monitoring"

    # alertmanager:
    #     image: prom/alertmanager:v0.26.0
    #     volumes:
    #         - ./alertmanager:/etc/alertmanager
    #     command:
    #         - '--config.file=/etc/alertmanager/config.yml'
    #         - '--storage.path=/alertmanager'
    #     restart: unless-stopped
    #     expose:
    #         - 9093
    #     networks:
    #         - local
    #     labels:
    #         org.label-schema.group: "monitoring"

    # caddy:
    #     image: caddy:2.7.5
    #     container_name: caddy
    #     ports:
    #         - "3000:3000"
    #         - "8080:8080"
    #         - "9090:9090"
    #         - "9093:9093"
    #         - "9091:9091"
    #     volumes:
    #         - ./caddy:/etc/caddy
    #     environment:
    #         - ADMIN_USER=${ADMIN_USER:-admin}
    #         - ADMIN_PASSWORD=${ADMIN_PASSWORD:-admin}
    #         - ADMIN_PASSWORD_HASH=${ADMIN_PASSWORD_HASH:-$2a$14$1l.IozJx7xQRVmlkEQ32OeEEfP5mRxTpbDTCTcXRqn19gXD8YK1pO}
    #     restart: unless-stopped
    #     networks:
    #         - local
    #     labels:
    #         org.label-schema.group: "monitoring"

networks:
    local:
        driver: bridge
